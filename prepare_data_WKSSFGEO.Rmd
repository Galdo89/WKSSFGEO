---
title: "Prepare tracking data"
author: "M.M.Rufino, T. Mendo and J.Egekvist"
date: "15/11/2021"
output: html_document
---


```{r setup, include=FALSE}

rm(list = ls())

# instalar os packages
# install.packages(c("ggplot2","sf","raster","RColorBrewer","viridis","gridExtra","dplyr","rasterVis","marmap","rnaturalearth))

# ploting
require(ggplot2)
require(RColorBrewer)
require(viridis)
require(gridExtra)

# spatial
require(sf)
require(raster)
require(mapview)

# gramatics and facilitators
require(dplyr)
require(lubridate) #for time series handler
#require(rnaturalearth)
#require(marmap)

# test line from MMR! Almost there :D I am now able to edit this github file! Happy me.

```

# Data preparation

This script aims to open the experimental dataset(s) and start exploring it within the WKSSFGEO.\

These data can be obtained from different devices, namely:
- Automatic Identification Systems (AIS)\
- GPS\
- Archipelago electronic monitoring system (permits to make the validation)\
- Video-based electronic monitoring (permits to make the validation and estimate landed resources)\
- Any trackers transmitting at least latitude, longitude, and a time stamp.\


## Data import

We will first import the data set, and check if it was well imported.
Then we will format the columns into the correct type (i.e. data, etc.) and make it a spatial object.\


1)     Define the extent of the study area and remove latitudes and longitudes outside this areaextent. 
Rationale: Some devices might send 0,0 messages for lats and longs when there is not good reception of satellites. Also, if using on-board observers or fishers that transport the devices you might get points in land if they turned them on before the trip.

2)     Remove duplicates. We check two sources of duplicates, for each vessel, we remove time_stamps that are the same. Then for each vessel, we remove latitudes and longitudes that are the same. These duplicates tend to occur more in AIS.


```{r open_data}

#######################
# Import the data from the url
kk1 <- read.csv("example_data_AIS.csv", head=TRUE, sep=",")
head(kk1)
summary(kk1)
dim(kk1)

# remove duplicates (there is no duplicated value):
kk1[duplicated(kk1),]

# or download the data and use:
# kk1 <- read.table("example_dataset.txt",sep=",")

kk1$vessel_id<-as.factor(kk1$vessel_id)
table(kk1$vessel_id, useNA = "always")

#######################
# format time cols
head(kk1$time_stamp)
head(kk1$data <- ymd_hms(kk1$time_stamp))
# OR:
# kk1$time_stamp<-as.POSIXct(as.character(kk1$time_stamp), format = "%Y-%m-%d %H:%M:%S")

# temporal duration
range(kk1$data)

# check difference between successive points (to redo after filtering perhaps)
kk1 %>% 
  group_by(vessel_id) %>% 
  summarise(diff=diff(data)) %>% 
  distinct(diff)


# Other situations:
# also check if you have any special code for missing values

# Note if we have a col for data and another for hours:
# head(kk1$data <- ymd_hms(paste(boats$data, substr(boats$record.time, 1, 8))))

# Note that if the dataset is imported from excel we might need to make something like this
# boats$data <- as.Date(as.numeric(boats$record.date), origin = "1899-12-30")

#######################
# Define the study area
dim(kk1)
#kk1 <- kk1 %>% 
#filter(lat>55,lon<0, lon>(-8))
#dim(kk1)

# Make a spatial object
head(kk1.sf <- st_as_sf(kk1, coords=c("lon","lat"),crs=4326, remove=FALSE))

kk1.sf %>% 
  group_by(vessel_id) %>% 
  summarize(do_union=FALSE) %>% 
  st_cast("LINESTRING") %>% 
  mapview()



```

**Alternatively**:

```{r}
library(tidyverse)
# remotes::install_github("Hafro/geo")
track <-
  read_csv("https://raw.githubusercontent.com/ices-eg/WKSSFGEO/main/example_data_AIS.csv") %>% 
  # save some downstream typing by using shorter variable names
  rename(vid = vessel_id, time = time_stamp) %>%  
  # unique rows
  distinct() %>% 
  distinct(vid, time, lon, lat, .keep_all = TRUE) %>% 
  # just in case
  arrange(vid, time) %>% 
  group_by(vid) %>% 
  mutate(duration = difftime(time, lag(time), units = "secs"),
         # warnings here are just because of the first datapoint
         distance = geo::arcdist(lat, lon, lag(lat), lag(lon), scale = "km") * 1000,
         # derived speed
         speed2 = distance / as.numeric(duration)) %>% 
  ungroup() %>% 
  st_as_sf(coords = c("lon", "lat"),
           crs = 4326,
           remove = FALSE)
```

```{r}
# alternative to mapview:
library(mapdeck) # greater control on points and things, one need though a token
#  to get a background map
mapdeck(location = c(11, 56.5), zoom = 8) %>% 
  add_scatterplot(data = track %>% sample_n(5e4),
                  lon = "lon", 
                  lat = "lat",
                  fill_colour = "speed",
                  legend = FALSE,
                  tooltip = "time",
                  layer_id = "points",
                  radius = 10,
                  radius_min_pixels = 2,
                  radius_max_pixels = 10,
                  update_view = FALSE,
                  stroke_opacity = 1,
                  palette = "inferno")
```



3)     Remove points on land – consider using a buffer as well, as the precision of the coordinates can vary depending on satellite reception. I generally apply 10 metres buffer and remove all points intersecting the coastline polygon. 
4)     Construct trajectories – Two options here: a) we need some information of the fishery – does it work during the day? Can we assume each day is a new trip? Then construct trajectories per day; b) Define when a vessel is in harbour using harbour polygons - A trip can then be defined as from the vessel leaves the harbour till et returnsJOSEFINE: polygon approach? (might need to interpolate first)
5)     Remove unrealistic speeds (I run a loop for this)
6)     Remove trips of specific duration or distance (again knowledge of the fishery required)
Identifying hauling activities
1)     Cut trajectories where distance between consecutive observations is above a threshold?
For example- 1000 metres
2)     Interpolation - specify frequency – 60 seconds?
3)     Remove points on land that might result from this interpolation
4)     Remove points at the beginning and end of trip (if ports are not known or vessels starting trips from the beach) – JOSEFINE: alternatively give list of ports and add buffer 
5)     Try: Random Forest, HMMs, EM algorithm, fixed threshold expert based or estimated with regretion trees – use speed instead of distance?



